python run_inference.py --model_name /shared/data2/jiaxinh3/LMSI/llama/model-13b --max_new_tokens 256 --prompt_file /shared/data2/jiaxinh3/LMSI/data/prompts/gsm8k/gsm8k_cot.txt --temperature 0.7 --top_k 40
